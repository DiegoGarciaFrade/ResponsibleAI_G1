{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigatin the Fairness Issues using Post-Processing: Threshold Adjustment\n",
    "\n",
    "This method tries to find (sensitive) group-specific thresholds for a given estimator. The thresholds are chosen to optimize the provided performance objective subject to the provided fairness constraints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, roc_auc_score\n",
    "from fairlearn.metrics import MetricFrame, selection_rate, demographic_parity_difference, equalized_odds_difference\n",
    "from fairlearn.metrics import demographic_parity_ratio, equalized_odds_ratio\n",
    "import seaborn as sns\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from sklearn.pipeline import Pipeline\n",
    "from fairlearn.reductions import DemographicParity, ExponentiatedGradient\n",
    "from fairlearn.postprocessing import ThresholdOptimizer, plot_threshold_optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# Generate synthetic features:\n",
    "# - Credit score (normally around 300-850)\n",
    "# - Annual income in thousands (normally around mean of $50k with std dev of $15k)\n",
    "# - Employment history in years (normally around 0-40)\n",
    "X = pd.DataFrame({\n",
    "    'Credit_Score': np.random.normal(650, 100, n),\n",
    "    'Annual_Income_k': np.random.normal(50, 15, n),\n",
    "    'Employment_History_y': np.random.normal(20, 10, n),\n",
    "    'Interest_Rate': np.random.normal(5, 1, n),\n",
    "    'Sex': np.random.choice([0, 1], n)  # 0 for 'Male', 1 for 'Female'\n",
    "})\n",
    "\n",
    "# Introduce a bias in the 'Interest_Rate' feature based on the sensitive attribute 'Sex'\n",
    "X.loc[X['Sex'] == 1, 'Interest_Rate'] += 2  # Females have higher interest rates on average\n",
    "\n",
    "# Introduce a strong bias in the label (loan approval) based on the sensitive attribute (sex)\n",
    "threshold_male = 1.5  # A relatively low bar for males\n",
    "threshold_female = 2.0  # A higher bar for females\n",
    "\n",
    "# Calculate a synthetic loan approval decision based on the financial features and bias\n",
    "\n",
    "y = pd.DataFrame({'Loan_Approval':np.zeros(X.shape[0])})\n",
    "y.loc[(X['Sex'] == 0) & (X['Credit_Score']/650 + X['Annual_Income_k']/50 > threshold_male), 'Loan_Approval'] = 1\n",
    "y.loc[(X['Sex'] == 1) & (X['Credit_Score']/650 + X['Annual_Income_k']/50 > threshold_female), 'Loan_Approval'] = 1\n",
    "\n",
    "selection_rates = MetricFrame(\n",
    "    metrics=selection_rate, y_true=y['Loan_Approval'], y_pred=y['Loan_Approval'], sensitive_features=X['Sex']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sensitive_train = X_train['Sex']\n",
    "sensitive_test = X_test['Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ThresholdOptimizer` receives a sklearn pipeline as input, that makes it more flexible with multi-step pipleines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"classifier\",RandomForestClassifier(random_state=42)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance objective and the fairness constraints should be decided as inputs to the threshold optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_optimizer = ThresholdOptimizer(\n",
    "    estimator=pipeline,\n",
    "    objective=\"balanced_accuracy_score\",\n",
    "    constraints=\"demographic_parity\",\n",
    ")\n",
    "threshold_optimizer.fit(X_train, y_train, sensitive_features=sensitive_train)\n",
    "\n",
    "plot_threshold_optimizer(threshold_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = threshold_optimizer.predict(X_test, sensitive_features=sensitive_test)\n",
    "\n",
    "# Measure accuracy\n",
    "accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    count,\n",
    "    false_negative_rate,\n",
    "    false_positive_rate,\n",
    "    selection_rate,\n",
    ")\n",
    "# Analyze metrics using MetricFrame\n",
    "metrics = {\n",
    "    \"accuracy\": balanced_accuracy_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"false positive rate\": false_positive_rate,\n",
    "    \"false negative rate\": false_negative_rate,\n",
    "    \"selection rate\": selection_rate,\n",
    "}\n",
    "metric_frame = MetricFrame(\n",
    "    metrics=metrics, y_true=y_test, y_pred=y_pred, sensitive_features=sensitive_test\n",
    ")\n",
    "metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    ylim=[0,1.05],\n",
    "    title=\"Show all metrics\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Statistical Parity\n",
    "stat_parity_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=sensitive_test)\n",
    "print(f\"Statistical Parity Difference: {stat_parity_diff}\")\n",
    "\n",
    "stat_parity_rto = demographic_parity_ratio(y_test, y_pred, sensitive_features=sensitive_test)\n",
    "print(f\"Statistical Parity ratio: {stat_parity_rto}\")\n",
    "\n",
    "# Equalized Odds\n",
    "equal_odds_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=sensitive_test)\n",
    "print(f\"Equalized Odds Difference: {equal_odds_diff}\")\n",
    "\n",
    "equal_odds_rto = equalized_odds_ratio(y_test, y_pred, sensitive_features=sensitive_test)\n",
    "print(f\"Equalized Odds Ratio: {equal_odds_rto}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.6:** Have a look at the documentation of threshold optimizer function in Fairlearn at https://fairlearn.org/v0.9/api_reference/generated/fairlearn.postprocessing.ThresholdOptimizer.html and learn more about how to use it. Use Equalized Odds (instead of demographic parity) as constraint and report the final results.\n",
    "\n",
    "**Exercise 4.7:** plot two scatter plots with balanced accuracy as x-axis and statistical parity difference/Equalized odds difference as y-axis for 6 different approaches we have presented in the lecture (naive approach, resampling, removing correlation, reweighting, exponentiated gradients, and threshold adjustment). Which one performs the best in this data? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
