{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigatin the Fairness Issues using In-Processing: Reweighting Data\n",
    "\n",
    "Here we need to use the models that accomodate sample weights. Then we try to give higher weights to the under-represented samples in our senstive group to increase their effect in the optimization process and hopefully learn models that are equalluy accurate for all sensitive groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, roc_auc_score\n",
    "from fairlearn.metrics import MetricFrame, selection_rate, demographic_parity_difference, equalized_odds_difference\n",
    "from fairlearn.metrics import demographic_parity_ratio, equalized_odds_ratio\n",
    "import seaborn as sns\n",
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "from sklearn.pipeline import Pipeline\n",
    "from fairlearn.reductions import DemographicParity, ExponentiatedGradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n = 1000\n",
    "\n",
    "# Generate synthetic features:\n",
    "# - Credit score (normally around 300-850)\n",
    "# - Annual income in thousands (normally around mean of $50k with std dev of $15k)\n",
    "# - Employment history in years (normally around 0-40)\n",
    "X = pd.DataFrame({\n",
    "    'Credit_Score': np.random.normal(650, 100, n),\n",
    "    'Annual_Income_k': np.random.normal(50, 15, n),\n",
    "    'Employment_History_y': np.random.normal(20, 10, n),\n",
    "    'Interest_Rate': np.random.normal(5, 1, n),\n",
    "    'Sex': np.random.choice([0, 1], n)  # 0 for 'Male', 1 for 'Female'\n",
    "})\n",
    "\n",
    "# Introduce a bias in the 'Interest_Rate' feature based on the sensitive attribute 'Sex'\n",
    "X.loc[X['Sex'] == 1, 'Interest_Rate'] += 2  # Females have higher interest rates on average\n",
    "\n",
    "# Introduce a strong bias in the label (loan approval) based on the sensitive attribute (sex)\n",
    "threshold_male = 1.5  # A relatively low bar for males\n",
    "threshold_female = 2.0  # A higher bar for females\n",
    "\n",
    "# Calculate a synthetic loan approval decision based on the financial features and bias\n",
    "\n",
    "y = pd.DataFrame({'Loan_Approval':np.zeros(X.shape[0])})\n",
    "y.loc[(X['Sex'] == 0) & (X['Credit_Score']/650 + X['Annual_Income_k']/50 > threshold_male), 'Loan_Approval'] = 1\n",
    "y.loc[(X['Sex'] == 1) & (X['Credit_Score']/650 + X['Annual_Income_k']/50 > threshold_female), 'Loan_Approval'] = 1\n",
    "\n",
    "selection_rates = MetricFrame(\n",
    "    metrics=selection_rate, y_true=y['Loan_Approval'], y_pred=y['Loan_Approval'], sensitive_features=X['Sex']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sensitive_train = X_train['Sex']\n",
    "sensitive_test = X_test['Sex']\n",
    "X_train = X_train.drop(columns=['Sex'])\n",
    "X_test = X_test.drop(columns=['Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we 1) Calculate the selection rate for each sensitive group in the training set, 2) Inversely proportion the weights to these selection rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate selection rate for each sensitive group\n",
    "selection_rate_male = y_train[sensitive_train == 0].mean()\n",
    "selection_rate_female = y_train[sensitive_train == 1].mean()\n",
    "\n",
    "# Calculate inverse of selection rate\n",
    "inverse_rate_male = 1 / selection_rate_male[0] if selection_rate_male[0] > 0 else 1\n",
    "inverse_rate_female = 1 / selection_rate_female[0] if selection_rate_female[0] > 0 else 1\n",
    "\n",
    "# Normalize the weights to make them sum to the number of samples (keeps the effective size of the dataset unchanged)\n",
    "normalization_factor = (len(y_train) / (inverse_rate_male * (sensitive_train == 0).sum() + inverse_rate_female * (sensitive_train == 1).sum()))\n",
    "\n",
    "# Create sample weights based on the sensitive feature\n",
    "sample_weights = np.ones(len(y_train))\n",
    "sample_weights[sensitive_train == 0] = inverse_rate_male * normalization_factor\n",
    "sample_weights[sensitive_train == 1] = inverse_rate_female * normalization_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest classifier with sample weights\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_prob = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure accuracy\n",
    "accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Measure AUC\n",
    "auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import (\n",
    "    MetricFrame,\n",
    "    count,\n",
    "    false_negative_rate,\n",
    "    false_positive_rate,\n",
    "    selection_rate,\n",
    ")\n",
    "# Analyze metrics using MetricFrame\n",
    "metrics = {\n",
    "    \"accuracy\": balanced_accuracy_score,\n",
    "    \"precision\": precision_score,\n",
    "    \"false positive rate\": false_positive_rate,\n",
    "    \"false negative rate\": false_negative_rate,\n",
    "    \"selection rate\": selection_rate,\n",
    "}\n",
    "metric_frame = MetricFrame(\n",
    "    metrics=metrics, y_true=y_test, y_pred=y_pred, sensitive_features=sensitive_test\n",
    ")\n",
    "metric_frame.by_group.plot.bar(\n",
    "    subplots=True,\n",
    "    layout=[3, 3],\n",
    "    legend=False,\n",
    "    figsize=[12, 8],\n",
    "    ylim=[0,1.05],\n",
    "    title=\"Show all metrics\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Statistical Parity\n",
    "stat_parity_diff = demographic_parity_difference(y_test, y_pred, sensitive_features=sensitive_test)\n",
    "print(f\"Statistical Parity Difference: {stat_parity_diff}\")\n",
    "\n",
    "stat_parity_rto = demographic_parity_ratio(y_test, y_pred, sensitive_features=sensitive_test)\n",
    "print(f\"Statistical Parity ratio: {stat_parity_rto}\")\n",
    "\n",
    "# Equalized Odds\n",
    "equal_odds_diff = equalized_odds_difference(y_test, y_pred, sensitive_features=sensitive_test)\n",
    "print(f\"Equalized Odds Difference: {equal_odds_diff}\")\n",
    "\n",
    "equal_odds_rto = equalized_odds_ratio(y_test, y_pred, sensitive_features=sensitive_test)\n",
    "print(f\"Equalized Odds Ratio: {equal_odds_rto}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.4:** Try increasing the weight for the femaple group and monitor the change in performance and fairness metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
